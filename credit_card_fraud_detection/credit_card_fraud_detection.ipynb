{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Fraud Detection\n",
    "\n",
    "Autora: Jéssica Ramos\n",
    "\n",
    "Dataset: https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entendendo a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "# leitura do dataset\n",
    "data = pd.read_csv('./data/creditcard.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Colunas do dataset:**\n",
    "\n",
    "- Time: Segundos entre a primeira transação do dataset e a transação em questão.\n",
    "- V1 a V28: Componentes principais obtidos das variáveis originais.\n",
    "- Amount: Valor da transação.\n",
    "- Class: A classificação da transação, sendo 1 = fraude e 0 = não fraude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medidas descritivas\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas as variáveis estão completas. 0.173% da base é composta de transações fraudulentas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** Criar um modelo de predição que classifique as transações como fraude ou não fraude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribuição das variáveis nos grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(variable):\n",
    "    sns.catplot(data = data, x = 'Class', y = variable, kind = 'box').set(title = variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('Amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável `Amount` é bastante assimétrica à direita. Vou aplicar uma transformação de log para ser mais fácil visualizar a distribuição. Como existe o valor 0 em amount, vou também adicionar 1 unidade no valor da variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_Amount'] = data['Amount'].apply(lambda x: math.log(x+1))\n",
    "\n",
    "boxplot('log_Amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As transações fraudulentas têm valores mais dispersos do que as transações legítimas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demais variáveis não têm interpertação direta associada, mas vou plotar os boxplots para ter uma ideia de separação entre os grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot('V28')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não existe clara separação na maioria das distribuições. Em geral, a classe de transações fraudulentas tem valores mais dispersos. Ambas as classes têm distribuições com muitos outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como as variáveis são resultado de PCA, não precisamos nos preocupar com colinearidades entre elas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação das bases de treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vou dividir a base usando 70% para treino e 30% para teste. As transações da base de teste serão as últimas, usando a variável Time como referência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcula o percentil\n",
    "perc70 = data[['Time']].quantile(0.7)\n",
    "perc70[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria a base de treino\n",
    "X_train = data[data['Time'] <= perc70[0]].copy()\n",
    "X_train.drop(['Class','Time','Amount'], axis = 1, inplace = True)\n",
    "y_train = data[data['Time'] <= perc70[0]]['Class'].copy()\n",
    "\n",
    "# cria a base de teste\n",
    "X_test = data[data['Time'] > perc70[0]].copy()\n",
    "X_test.drop(['Class','Time','Amount'], axis = 1, inplace = True)\n",
    "y_test = data[data['Time'] > perc70[0]]['Class'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preditores treino\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preditores teste\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribução do target na base de treino\n",
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribução do target na base de teste\n",
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de treino tem 199.368 observações, sendo 0.193% fraudes. A base de teste tem 85.439 observações, sendo 0.126% fraudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrigindo o desbalanceamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de treino é muito desbalanceada, o que pode fazer os resultados não serem muito bons para a classe positiva.Para tentar corrigir o desbalanceamento, vou aplicar SMOTE apenas na classe positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE(sampling_strategy = 'minority') # apenas afeta a classe positiva\n",
    "X_train_new, y_train_new = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultado\n",
    "y_train_new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nova base gerada tem 397.968 observações, sendo 50% transações fraudulentas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Logístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vou ajustar um modelo logístico tradicional. As métricas de referência serão recall, specificity (recall da categoria negativa) e precision.\n",
    "\n",
    "Escolhi o recall como métrica principal pensando num problema de fraudes em que transações com alto risco de fraude passariam por uma segunda autenticação. Portanto, é importante que as transações de fato fraudulentas tenham risco alto, ainda que existam vários falsos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit do modelo logístico\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_new, y_train_new)\n",
    "\n",
    "# predições\n",
    "y_pred_train_lr = lr.predict(X_train_new)\n",
    "y_pred_test_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métricas de treino\n",
    "metric_train_lr = precision_recall_fscore_support(y_train_new, y_pred_train_lr)\n",
    "\n",
    "print('Precision: ', metric_train_lr[0][1],\n",
    "      '\\nRecall: ', metric_train_lr[1][1],\n",
    "      '\\nSpecificity: ', metric_train_lr[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métricas de teste\n",
    "metric_test_lr = precision_recall_fscore_support(y_test, y_pred_test_lr)\n",
    "\n",
    "print('Precision: ', metric_test_lr[0][1],\n",
    "      '\\nRecall: ', metric_test_lr[1][1],\n",
    "      '\\nSpecificity: ', metric_test_lr[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observações classificadas como positivas\n",
    "y_pred_test_lr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo logístico acertou 89.8% das observações fraudulentas e 97.4% das não fraudulentas na base de teste. Dentre as 2.7% de observações classificadas como fraude, 4.1% são de fato fraudes.\n",
    "\n",
    "O modelo por default já considera regularização l2. Posso tentar otimizar o parâmetro usando cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define valores de C para testar\n",
    "params_l2 = {'C': [10.0, 5.0, 2.0, 1.5, 1.0, 0.8, 0.5, 0.1, 0.01, 0.001]} # quanto menor, maior o peso do termo L2\n",
    "\n",
    "l2_grid = GridSearchCV(estimator = LogisticRegression(),\n",
    "                       param_grid = params_l2,\n",
    "                       scoring = 'recall',\n",
    "                       cv = 10,\n",
    "                       verbose = 2)\n",
    "\n",
    "# ajusta\n",
    "l2_grid.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultado\n",
    "pd.DataFrame(l2_grid.cv_results_).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variação entre os resultados é de fato bem pequena. Portanto vou manter o modelo default que já ajustamos como o melhor resultado para a regressão logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo linear teve resultados bons, mas vou tentar melhorar o resultado com uma Random Forest. Existem vários parâmetros que podem ser otimizados, portanto usarei cross validation e uma random grid search para encontrar a melhor combinação.\n",
    "\n",
    "Os valores na lista de busca são bem arbitrários, fui alterando à medida que rodei alguns resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# define a grid de hiperparâmetos\n",
    "params_rf = {'n_estimators': [100, 200, 300, 500, 800, 1000], # número de árvores\n",
    "             'max_depth': [3, 4, 5, 6, 7, 8], # profundidade máxima de cada arvore\n",
    "             'min_samples_leaf': [5, 6, 7, 10, 15, 20], # mínimo de amostras por folha\n",
    "             'max_features': [0.7, 0.8, 0.9, 1.0]} # proporção das features consideradas em cada split\n",
    "\n",
    "rf_grid = RandomizedSearchCV(estimator = RandomForestClassifier(),\n",
    "                             param_distributions = params_rf,\n",
    "                             scoring = 'recall',\n",
    "                             n_iter = 5,\n",
    "                             cv = 5,\n",
    "                             random_state = 10,\n",
    "                             verbose = 2)\n",
    "\n",
    "# ajusta\n",
    "rf_grid.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultado\n",
    "pd.DataFrame(rf_grid.cv_results_).sort_values(by = 'rank_test_score').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melhor modelo\n",
    "rf = rf_grid.best_estimator_\n",
    "\n",
    "# predições\n",
    "y_pred_train_rf = rf.predict(X_train_new)\n",
    "y_pred_test_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métricas de treino\n",
    "metric_train_rf = precision_recall_fscore_support(y_train_new, y_pred_train_rf)\n",
    "\n",
    "print('Precision: ', metric_train_rf[0][1],\n",
    "      '\\nRecall: ', metric_train_rf[1][1],\n",
    "      '\\nSpecificity: ', metric_train_rf[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métricas de teste\n",
    "metric_test_rf = precision_recall_fscore_support(y_test, y_pred_test_rf)\n",
    "\n",
    "print('Precision: ', metric_test_rf[0][1],\n",
    "      '\\nRecall: ', metric_test_rf[1][1],\n",
    "      '\\nSpecificity: ', metric_test_rf[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenta os resultados aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vou avaliar também um Gradient Boosting. Também faço aqui a busca por hiperparâmetros ótimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# define a grid de hiperparâmetos\n",
    "params_gb = {'learn_rate': [0.1, 0.05, 0.01, 0.001], # taxa de aprendizado\n",
    "             'n_estimators': [100, 200, 300, 500, 800, 1000], # número de árvores\n",
    "             'max_depth': [3, 4, 5, 6, 7, 8], # profundidade máxima de cada arvore\n",
    "             'min_samples_leaf': [5, 6, 7, 10, 15, 20], # mínimo de amostras por folha\n",
    "             'max_features': [0.7, 0.8, 0.9, 1.0]} # proporção das features consideradas em cada split\n",
    "\n",
    "gb_grid = RandomizedSearchCV(estimator = GradientBoostingClassifier(),\n",
    "                             param_distributions = params_rf,\n",
    "                             scoring = 'recall',\n",
    "                             n_iter = 5,\n",
    "                             cv = 5,\n",
    "                             random_state = 10,\n",
    "                             verbose = 2)\n",
    "\n",
    "# ajusta\n",
    "gb_grid.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultado\n",
    "pd.DataFrame(gb_grid.cv_results_).sort_values(by = 'rank_test_score').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melhor modelo\n",
    "gb = gb_grid.best_estimator_\n",
    "\n",
    "# predições\n",
    "y_pred_train_gb = rf.predict(X_train_new)\n",
    "y_pred_test_gb = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métricas de treino\n",
    "metric_train_gb = precision_recall_fscore_support(y_train_new, y_pred_train_gb)\n",
    "\n",
    "print('Precision: ', metric_train_gb[0][1],\n",
    "      '\\nRecall: ', metric_train_gb[1][1],\n",
    "      '\\nSpecificity: ', metric_train_gb[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métricas de teste\n",
    "metric_test_gb = precision_recall_fscore_support(y_test, y_pred_test_gb)\n",
    "\n",
    "print('Precision: ', metric_test_gb[0][1],\n",
    "      '\\nRecall: ', metric_test_gb[1][1],\n",
    "      '\\nSpecificity: ', metric_test_gb[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenta os resultados aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados finais do melhor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até então os modelos foram avaliados classificando como categoria 1 (fraude) as transações com probabilidade estimada > 0.5 e 0 caso contrário. Posso agora avaliar a distribuição da probabilidade estimada do melhor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dar uma analisada na distribuição aqui, definir outro corte se parecer melhor, exibir as métricas finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisar variáveis de maior importância pro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concluir a análise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
